source $DILATED_CNN_NER_ROOT/conf/global.conf

export network="dilated-doc"
export model_dir="$models_dir/$network"

source $DILATED_CNN_NER_ROOT/conf/lample-embeddings.conf

# model hyperparameters
num_filters=300
filter_width=3
nonlinearity="relu"
initialization="identity"
shape_dim=5
documents="true"
start_end="false"
predict_pad="true"
frontend_batch_norm="False"
frontend_residuals="0"

# use CoNLL-2003 data -- load this AFTER filter_width is set
source $DILATED_CNN_NER_ROOT/conf/conll/conll2003-v4.conf

pretrained_model="$DILATED_CNN_NER_ROOT/models/dilated-cnn-best"

layers="{'conv1': {'dilation': 1, 'width': $filter_width, 'filters': $num_filters, 'initialization': '$initialization', 'take': false}, \
         'conv2': {'dilation': 2, 'width': $filter_width, 'filters': $num_filters, 'initialization': '$initialization', 'take': false}, \
         'conv3': {'dilation': 1, 'width': $filter_width, 'filters': $num_filters, 'initialization': '$initialization', 'take': true}}"

block_repeats=3

# training hyperparameters
lr=0.001
hidden_dropout=0.75
input_dropout=0.75
middle_dropout=1.0
word_dropout=0.75
batch_size=32
loss=block
#clip_grad=10
l2=0.0
drop_penalty=1e-4
epsilon=1e-4
loss=block
beta2=0.99
